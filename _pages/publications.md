---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<style>
a:link {
  text-decoration: none;
}

a:visited {
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

a:active {
  text-decoration: underline;
}
</style>

<!-- {% if author.googlescholar %}
  You can also find my articles on [my Google Scholar profile](https://scholar.google.com/citations?user=VWCZLXgAAAAJ&hl=en).
{% endif %}

{% include base_path %}

{% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %} -->

<!-- You can find my published articles on my [Google Scholar](https://scholar.google.com/citations?user=VWCZLXgAAAAJ&hl=en) profile. -->

<h2>Conference/Journal Papers</h2>
<table id="gsc_a_t">
	<tbody id="gsc_a_b">
		<tr class="gsc_a_tr" style="background-color:#E0FFFF"> 
			<td class="gsc_a_t"><a href="https://leiwangr.github.io/files/ijcv-preprint.pdf"><strong><span class="gsc_a_at">Meet JEANIE: a Similarity Measure for 3D Skeleton Sequences via Temporalâ€‘Viewpoint Alignment</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong>, J Liu, L Zheng, T Gedeon, P Koniusz</div>
				<div class="gs_gray">International Journal of Computer Vision (IJCV)</div>
			</td>
			<td class="gsc_a_c">(an extension of our ACCV&#39;22)<br>[<font color="red"><strong>IF: 19.5</strong>, coming soon</font>]</td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2023</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#E0FFFF"> 
			<td class="gsc_a_t"><a href="https://arxiv.org/pdf/2110.05216.pdf"><strong><span class="gsc_a_at">High-order Tensor Pooling with Attention for Action Recognition</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong>, K Sun, P Koniusz</div>
				<div class="gs_gray">IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</div>
			</td>
			<td class="gsc_a_c">(an extension of our TPAMI&#39;20)<br>[<font color="red"><strong>B</strong>, accepted</font>] <br><a href="https://github.com/LeiWangR/HoTP" style="color:#000000;"> Code (preprocessing)</a></td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2023</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#E0FFFF"> 
			<td class="gsc_a_t"><a href="https://arxiv.org/pdf/2310.10059.pdf"><strong><span class="gsc_a_at">Flow Dynamics Correction for Action Recognition</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong>, P Koniusz</div>
				<div class="gs_gray">IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</div>
			</td>
			<td class="gsc_a_c">[<font color="red"><strong>B</strong>, accepted</font>]</td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2023</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#E0FFFF">
			<td class="gsc_a_t"><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_3Mformer_Multi-Order_Multi-Mode_Transformer_for_Skeletal_Action_Recognition_CVPR_2023_paper.pdf"><strong><span class="gsc_a_at">3Mformer: Multi-order Multi-mode Transformer for Skeletal Action Recognition</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong>, P Koniusz</div>
				<div class="gs_gray">Computer Vision and Pattern Recognition (CVPR), 5620-5631</div>
			</td>
			<td class="gsc_a_c">[<font color="red"><strong>A*</strong></font>]</td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2023</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#E0FFFF">
			<td class="gsc_a_t"><a href="https://openaccess.thecvf.com/content/ACCV2022/papers/Wang_Temporal-Viewpoint_Transportation_Plan_for_Skeletal_Few-shot_Action_Recognition_ACCV_2022_paper.pdf"><strong><span class="gsc_a_at">Temporal-Viewpoint Transportation Plan for Skeletal Few-shot Action Recognition</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong>, P Koniusz</div>
				<div class="gs_gray">Asian Conference on Computer Vision (ACCV), 307-326</div>
			</td>
			<td class="gsc_a_c">[<font color="red"><strong>B</strong>, oral, 4.9% acceptance rate, <br><strong>Best Student Paper Award</strong></font>]<!-- <br><a href="" style="color:#008000;">Codes</a> --> </td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2022</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#E0FFFF">
			<td class="gsc_a_t"><a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136810174.pdf"><strong><span class="gsc_a_at">Uncertainty-DTW for Time Series and Sequences</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong>, P Koniusz</div>
				<div class="gs_gray">European Conference on Computer Vision (ECCV), 176-195</div>
			</td>
			<td class="gsc_a_c">[<font color="red"><strong>A*</strong>, oral, 2.7% acceptance rate</font>]<br><a href="https://github.com/LeiWangR/uDTW" style="color:#000000;">Code</a></td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2022</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#E5E4E2">
			<td class="gsc_a_t"><a href="https://ieeexplore.ieee.org/document/9895208"><strong><span class="gsc_a_at">Fusing Higher-Order Features in Graph Neural Networks for Skeleton-Based Action Recognition</span></strong></a>
				<div class="gs_gray">Z Qin, Y Liu, P Ji, D Kim, <strong>L Wang</strong>, B McKay, S Anwar, T Gedeon</div>
				<div class="gs_gray">IEEE Transactions on Neural Networks and Learning Systems (TNNLS), (Early Access)</div>
			</td>
			<td class="gsc_a_c">[<strong><font color="red">IF: 14.255</font></strong>]<br><a href="https://github.com/harutatsuakiyama/Angular-Skeleton-Encoding" style="color:#000000;">Code</a></td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#E0FFFF">
			<td class="gsc_a_t"><a href="https://dl.acm.org/doi/10.1145/3474085.3475572"><strong><span class="gsc_a_at">Self-supervising Action Recognition by Statistical Moment and Subspace Descriptors</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong>, P Koniusz</div>
				<div class="gs_gray">ACM International Conference on Multimedia (ACM-MM), 4324-4333</div>
			</td>
			<td class="gsc_a_c">[<strong><font color="red">A*</font></strong>]<br><a href="https://github.com/LeiWangR/ODFSDF" style="color:#000000;">Code</a></td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#E0FFFF">
			<td class="gsc_a_t"><strong data-bind="text: title"><a href="https://ieeexplore.ieee.org/document/9521829">Tensor Representations for Action Recognition</a></strong>
				<div class="gs_gray">P Koniusz,<strong> L Wang</strong>, A Cherian</div>
				<div class="gs_gray">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) 44 (2), 648-665</div>
			</td>
			<td class="gsc_a_c">[<strong><font color="red">IF: 24.314</font></strong>]</td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#E0FFFF">
			<td class="gsc_a_t"><a href="https://ieeexplore.ieee.org/document/8753686"><strong><span class="gsc_a_at">A Comparative Review of Recent Kinect-based Action Recognition Algorithms</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong>, DQ Huynh, P Koniusz</div>
				<div class="gs_gray">IEEE Transactions on Image Processing (TIP) 29 (1), 15-28</div>
			</td>
			<td class="gsc_a_c">[<strong><font color="red">IF: 11.041</font></strong>]<br><a href="https://github.com/LeiWangR/HDG" style="color:#000000;">Dataset & Code</a></td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#E0FFFF">
			<td class="gsc_a_t"><a href="https://ieeexplore.ieee.org/document/9008573"><strong data-bind="text: title">Hallucinating IDT Descriptors and I3D Optical Flow Features for Action Recognition with CNNs</strong></a>
				<div class="gs_gray"><strong>L Wang</strong>, P Koniusz, DQ Huynh</div>
				<div class="gs_gray">IEEE International Conference on Computer Vision (ICCV), 8698-8708</div>
			</td>
			<td class="gsc_a_c">[<strong><font color="red">A*</font></strong>]</td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#FFFFE0">
			<td class="gsc_a_t"><a href="https://ieeexplore.ieee.org/document/8803051"><strong><span class="gsc_a_at">Loss Switching Fusion with Similarity Search for Video Classification</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong>, DQ Huynh, MR Mansour</div>
				<div class="gs_gray">26th IEEE International Conference on Image Processing (ICIP), 974-978</div>
			</td>
			<td class="gsc_a_c">[<strong><font color="red">B</font></strong><font color="red">, industrial research <br>+ 1 AU<strong>&nbsp;patent</strong></font>]<br><a href="https://github.com/LeiWangR/LSFNet" style="color:#000000;">Our dataset</a></td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td>
		</tr>
	</tbody>
</table>
<!-- <h3>&nbsp;</h3> -->
<h2>Patents</h2>
<table id="gsc_a_t">
	<tbody id="gsc_a_b">
		<tr class="gsc_a_tr" style="background-color:#FFFFE0">
			<td class="gsc_a_t"><a href=""><strong><span class="gsc_a_at">System and Method of Detecting Anomalies from Mass Data</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong></div>
				<div class="gs_gray">US patent (provisional, SN 63/326,525)</div>
			</td>
<!-- 			<td class="gsc_a_c">&nbsp;</td> -->
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2022</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#FFFFE0">
			<td class="gsc_a_t"><a href="http://pericles.ipaustralia.gov.au/ols/auspat/applicationDetails.do?applicationNo=2019903775"><strong><span class="gsc_a_at">Method and System for Classifying Video Data</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong>, G Woods</div>
				<div class="gs_gray">AU Patent AU 2,019,903,775</div>
			</td>
<!-- 			<td class="gsc_a_c">&nbsp;</td> -->
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#FFFFE0">
			<td class="gsc_a_t"><a href="http://pericles.ipaustralia.gov.au/ols/auspat/applicationDetails.do?applicationNo=2019900316"><strong><span class="gsc_a_at">System and Method of Video Data Retrieval</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong>, M Reda Mansour, G Woods</div>
				<div class="gs_gray">AU Patent AU 2,019,900,316</div>
			</td>
<!-- 			<td class="gsc_a_c">&nbsp;</td> -->
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td>
		</tr>
	</tbody>
</table>
<h2>Theses</h2>
<table id="gsc_a_t">
	<tbody id="gsc_a_b">
		<tr class="gsc_a_tr" style="background-color:#FFE4E1">
			<td class="gsc_a_t"><a href="https://openresearch-repository.anu.edu.au/bitstream/1885/301236/1/ANU_PhD_Thesis_corrected.pdf"><strong><span class="gsc_a_at">Robust Human Action Modelling</span></strong></a><br />
				<div class="gs_gray"><strong>L Wang</strong></div>
				<div class="gs_gray">PhD thesis<font color="blue">*</font>, The Australian National University</div>
			</td>
<!-- 			<td class="gsc_a_c">&nbsp;</td> -->
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">Nov 2023</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#FFE4E1">
			<!-- https://www.researchgate.net/profile/Lei_Wang51/publication/332369012_Analysis_and_Evaluation_of_Kinect-based_Action_Recognition_Algorithms/links/5cb001be4585156cd7916b18/Analysis-and-Evaluation-of-Kinect-based-Action-Recognition-Algorithms.pdf -->
			<td class="gsc_a_t"><a href="https://arxiv.org/pdf/2112.08626.pdf"><strong><span class="gsc_a_at">Analysis and Evaluation of Kinect-based Action Recognition Algorithms</span></strong></a><br />
				<div class="gs_gray"><strong>L Wang</strong></div>
				<div class="gs_gray">Master&rsquo;s thesis, The University of Western Australia</div>
			</td>
<!-- 			<td class="gsc_a_c">&nbsp;</td> -->
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">Nov 2017</span></td>
		</tr>
	</tbody>
</table>
<p style="font-family:Arial; font-size: 12px; color: blue">
*: I would like to extend my heartfelt gratitude to three esteemed PhD thesis examiners, namely <a href="https://lingqiao-adelaide.github.io/lingqiaoliu.github.io/">Dr. Lingqiao Liu</a> (University of Adelaide) and <a href="https://wp8619.github.io/">Dr. Peng Wang</a> (University of Electronic Science and Technology of China), as well as an anonymous examiner, for their invaluable insights, meticulous examination, and constructive feedback on my research work.
</p>
 
<!-- <p>&nbsp;</p> -->
<h2>arXiv preprints</h2>
<table id="gsc_a_t">
	<tbody id="gsc_a_b">
		<tr class="gsc_a_tr">
			<td class="gsc_a_t"><a href="https://leiwangr.github.io/files/taylor-videos.pdf"><strong><span class="gsc_a_at">Taylor Videos for Action Recognition</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong>, X Yuan, T Gedeon, L Zheng</div>
				<div class="gs_gray">Research report</div>
			</td>
			<td class="gsc_a_c">Xiuyuan Yuan conducted the research under the supervision of Dr. Lei Wang in the ANU Summer Scholars Program. Xiuyuan Yuan is supported by a Summer Research Internship provided by the ANU School of Computing.</td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2024</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#FFFFE0">
			<td class="gsc_a_t"><a href="https://leiwangr.github.io/files/researchreport24.pdf"><strong><span class="gsc_a_at">Advancing Anomaly Detection: An Adaptation Model and a New Dataset</span></strong></a>
				<div class="gs_gray">L Zhu, A Raj, <strong>L Wang</strong></div>
				<div class="gs_gray">Research report</div>
			</td>
			<td class="gsc_a_c">Liyun Zhu and Arjun Raj are recipients of research sponsorship from Active Intelligence Australia Pty Ltd in Perth, Western Australia, which includes The Active Intelligence Research Challenge Award.</td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2024</span></td>
		</tr>
		<tr class="gsc_a_tr"> <!--  style="background-color:#E0FFFF" -->
			<td class="gsc_a_t"><a href="https://arxiv.org/pdf/2310.05615.pdf"><strong><span class="gsc_a_at">Adaptive Multi-head Contrastive Learning</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong>, P Koniusz, T Gedeon, L Zheng</div>
				<div class="gs_gray">arXiv preprint arXiv:2310.05615</div>
			</td>
			<td class="gsc_a_c">Technical report</td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2023</span></td>
		</tr>
		<tr class="gsc_a_tr" style="background-color:#E0FFFF">
			<td class="gsc_a_t"><a href="https://arxiv.org/pdf/2112.12668.pdf"><strong><span class="gsc_a_at">3D Skeleton-based Few-shot Action Recognition with JEANIE is not so NaÃ¯ve</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong>, J Liu, P Koniusz</div>
				<div class="gs_gray">arXiv preprint arXiv:2112.12668</div>
			</td>
			<td class="gsc_a_c">(an extended version has been <br>accepted by ACCV&#39;22 [oral])</td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td>
		</tr>
		<tr class="gsc_a_tr">
			<td class="gsc_a_t"><a href="https://arxiv.org/pdf/2309.15768.pdf"><strong><span class="gsc_a_at">AI in Software Engineering: Case Studies and Prospects</span></strong></a>
				<div class="gs_gray"><strong>L Wang</strong></div>
				<div class="gs_gray">arXiv preprint arXiv:2309.15768</div>
			</td>
			<td class="gsc_a_c">Technical Report. The author conducted this work while enrolled as a master's student at UWA, specifically for the CITS5502 Software Processes unit in 2017.</td>
			<td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td>
		</tr>
	</tbody>
</table>
<p>&nbsp;</p>

<font size="3" color="blue">
	Light cyan highlights the research works during my PhD candidature and light yellow highlights my industrial research works.
	My theses are in misty rose color and other collaborative research works are in platinum color.
	Last updated: 12/01/2024.	
</font>
